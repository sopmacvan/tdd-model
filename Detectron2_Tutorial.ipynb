{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QHnVupBBn9eR"},"source":["# Detectron2 Beginner's Tutorial\n","\n","<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n","\n","Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n","* Run inference on images or videos, with an existing detectron2 model\n","* Train a detectron2 model on a new dataset\n","\n","You can make a copy of this tutorial by \"File -> Open in playground mode\" and make changes there. __DO NOT__ request access to this tutorial.\n"]},{"cell_type":"markdown","source":["# Go to git repository"],"metadata":{"id":"qrDnJqCf_v-x"}},{"cell_type":"code","source":["from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","tdd_path = \"/content/drive/MyDrive/Tufts Dental Database\"\n","repo_path = \"/content/drive/MyDrive/Github/tdd-model\"\n","destination_path = f\"{repo_path}/dataset\"\n","# !cp -r \"$tdd_path\" \"$destination_path\"\n","%cd \"$repo_path\"\n","%ls"],"metadata":{"id":"Equ4Yyck_zCo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vM54r6jlKTII"},"source":["# Install detectron2"]},{"cell_type":"code","source":["import locale\n","import sys, os, distutils.core\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"MdOXUsXufaDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json"],"metadata":{"id":"92s-sPSNoylE"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FsePPpwZSmqt"},"source":["%%time\n","%pip install pyyaml==5.1\n","# # # Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n","# # # See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n","# # !git clone 'https://github.com/facebookresearch/detectron2'\n","# # dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","# # !python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","# # sys.path.insert(0, os.path.abspath('./detectron2'))\n","\n","# # # Properly install detectron2. (Please do not install twice in both ways)\n","# # %pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","\n","# # Or, to install it from a local clone:\n","# !git clone https://github.com/facebookresearch/detectron2.git\n","%pip install -e detectron2"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"],"metadata":{"id":"0d288Z2mF5dC"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZyAvNCJMmvFF"},"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vk4gID50K03a"},"source":["# Run a pre-trained detectron2 model"]},{"cell_type":"markdown","metadata":{"id":"JgKyUL4pngvE"},"source":["We first download an image from the COCO dataset:"]},{"cell_type":"code","metadata":{"id":"dq9GY37ml1kr"},"source":["# !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n","# im = cv2.imread(\"./input.jpg\")\n","# cv2_imshow(im)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uM1thbN-ntjI"},"source":["Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."]},{"cell_type":"code","metadata":{"id":"HUjkwRsOn1O0"},"source":["# cfg = get_cfg()\n","# # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n","# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n","# # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n","# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","# predictor = DefaultPredictor(cfg)\n","# outputs = predictor(im)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7d3KxiHO_0gb"},"source":["# # look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n","# print(outputs[\"instances\"].pred_classes)\n","# print(outputs[\"instances\"].pred_boxes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8IRGo8d0qkgR"},"source":["# # We can use `Visualizer` to draw the predictions on the image.\n","# v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","# out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","# cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b2bjrfb2LDeo"},"source":["# Train on a custom dataset"]},{"cell_type":"markdown","metadata":{"id":"tjbUIhSxUdm_"},"source":["In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n","\n","We use [the balloon segmentation dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)\n","which only has one class: balloon.\n","We'll train a balloon segmentation model from an existing model pre-trained on COCO dataset, available in detectron2's model zoo.\n","\n","Note that COCO dataset does not have the \"balloon\" category. We'll be able to recognize this new class in a few minutes.\n","\n","## Prepare the dataset"]},{"cell_type":"markdown","metadata":{"id":"tVJoOm6LVJwW"},"source":["Register the balloon dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n","Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.\n"]},{"cell_type":"code","source":["from detectron2.structures import BoxMode\n","from utils.dataset import get_abnormality_dicts, create_train_val_split, get_class_counts\n","import pickle"],"metadata":{"id":"KGnNFWkZf6O0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","repo_path = '/content/drive/MyDrive/Github/tdd-model/dataset'\n","train_path = os.path.join(repo_path, 'train.pkl')\n","val_path = os.path.join(repo_path, 'val.pkl')\n","if os.path.exists(train_path) and os.path.exists(val_path):\n","  with open(train_path, 'rb') as f:\n","    train = pickle.load(f)\n","  with open(val_path, 'rb') as f:\n","    val = pickle.load(f)\n","else:\n","  dataset_dicts = get_abnormality_dicts(repo_path, BoxMode.XYWH_ABS)\n","  train, val = create_train_val_split(dataset_dicts, train_path, val_path)"],"metadata":{"id":"M0OCPBrigMyg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# register dataset\n","# DatasetCatalog.remove('abnormalities_train')\n","# DatasetCatalog.remove('abnormalities_val')\n","DatasetCatalog.register('abnormalities_train', lambda: train)\n","DatasetCatalog.register('abnormalities_val', lambda: val)\n","\n","MetadataCatalog.get('abnormalities').set(thing_classes=['benign_cyst_neoplasia', 'malignant_neoplasia', 'inflammation', 'dysplasia', 'metabolic/systemic', 'trauma', 'developmental'],\n","                                               thing_colors=[(255, 127, 80), (255, 0, 0), (255, 215, 0), (0, 255, 255), (128, 0, 128), (255, 160, 122), (100, 149, 237)])\n","abnormalities_metadata = MetadataCatalog.get(\"abnormalities\")"],"metadata":{"id":"BZjjm9hdmk4N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ljbWTX0Wi8E"},"source":["To verify the dataset is in correct format, let's visualize the annotations of randomly selected samples in the training set:\n","\n"]},{"cell_type":"code","metadata":{"id":"UkNbUzUOLYf0"},"source":["# dataset_dicts = get_balloon_dicts(\"balloon/train\")\n","dataset_dicts = DatasetCatalog.get('abnormalities_train')\n","for d in random.sample(dataset_dicts, 3):\n","    print(d[\"file_name\"][-8:])\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=abnormalities_metadata, scale=0.5)\n","    out = visualizer.draw_dataset_dict(d)\n","    out_img = out.get_image()[:, :, ::-1]\n","    resized_img = cv2.resize(out_img, (0, 0), fx=0.5, fy=0.5)\n","\n","    cv2_imshow(resized_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wlqXIXXhW8dA"},"source":["## Train!\n","\n","Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~2 minutes to train 300 iterations on a P100 GPU.\n"]},{"cell_type":"code","source":["import detectron2.data.transforms as T\n","from detectron2.data import DatasetMapper   # the default mapper\n","from detectron2.engine import DefaultTrainer\n","from detectron2.data import build_detection_train_loader, build_detection_test_loader\n","\n","augmentation = [\n","    T.RandomFlip(horizontal=True, vertical=False, prob=0.5),\n","    T.RandomContrast(0.5, 1.5),\n","    T.RandomApply(tfm_or_aug=T.RandomCrop(\"absolute\", (84, 161)),\n","                      prob=0.5)\n","]\n","\n","class CustomTrainer(DefaultTrainer):\n","  @classmethod\n","  def build_train_loader(cls, cfg):\n","    return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=augmentation))\n","  @classmethod\n","  def build_test_loader(cls, cfg, dataset_name):\n","    return build_detection_test_loader(cfg, dataset_name, mapper=DatasetMapper(cfg, False))"],"metadata":{"id":"iZwTu-PL9Gta"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7unkuuiqLdqd"},"source":["%%time\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"abnormalities_train\",)\n","cfg.DATASETS.TEST = (\"abnormalities_val\")\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n","\n","cfg.SOLVER.IMS_PER_BATCH = 4  # 2, This is the real \"batch size\" commonly known to deep learning people\n","cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n","cfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset, (1 epoch= total/batch size, 60 iter= 238/4)\n","cfg.SOLVER.STEPS = []        # do not decay learning rate\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n","cfg.INPUT.MASK_FORMAT = \"bitmask\"\n","# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = CustomTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"qz-DDSTV7N40"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hBXeH8UXFcqU"},"source":["# Look at training curves in tensorboard:\n","%load_ext tensorboard\n","%tensorboard --logdir output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0e4vdDIOXyxF"},"source":["## Inference & evaluation using the trained model\n","Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:\n","\n"]},{"cell_type":"code","metadata":{"id":"Ya5nEuMELeq8"},"source":["# Inference should use the config with parameters that are used in training\n","# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.10   # confidence\n","cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.45 # iou\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qWq1XHfDWiXO"},"source":["Then, we randomly select several samples to visualize the prediction results."]},{"cell_type":"code","metadata":{"id":"U5LhISJqWXgM"},"source":["from detectron2.utils.visualizer import ColorMode\n","dataset_dicts = DatasetCatalog.get('abnormalities_val')\n","with_abnormalities = [obj for obj in dataset_dicts if obj['annotations']]\n","# for d in random.sample(dataset_dicts, 3):\n","for d in with_abnormalities:\n","    name = d[\"file_name\"][-8:]\n","\n","    # prediction\n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=abnormalities_metadata,\n","                   scale=0.5,\n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n","    )\n","    pred_out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    pred_out = pred_out.get_image()[:, :, ::-1]\n","    # cv2_imshow(pred_out.get_image()[:, :, ::-1])\n","\n","    # label\n","    im = cv2.imread(d[\"file_name\"])\n","    v = Visualizer(im[:, :, ::-1],\n","                            metadata=abnormalities_metadata,\n","                            scale=0.5)\n","    label_out = visualizer.draw_dataset_dict(d)\n","    label_out = label_out.get_image()[:, :, ::-1]\n","    # cv2_imshow(label_out.get_image()[:, :, ::-1])\n","\n","\n","    # plot prediction and label side-by-side\n","    fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n","    ax[0].imshow(img1)\n","    ax[1].imshow(img2)\n","    plt.title(f'prediction vs label ({name})')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for d in with_abnormalities:\n","#     print(d[\"file_name\"][-8:])\n","#     img = cv2.imread(d[\"file_name\"])\n","#     visualizer = Visualizer(img[:, :, ::-1], metadata=abnormalities_metadata, scale=0.5)\n","#     out = visualizer.draw_dataset_dict(d)\n","#     cv2_imshow(out.get_image()[:, :, ::-1])"],"metadata":{"id":"VD5D3H47GFvy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kblA1IyFvWbT"},"source":["We can also evaluate its performance using AP metric implemented in COCO API.\n","This gives an AP of ~70. Not bad!"]},{"cell_type":"code","metadata":{"id":"h9tECBQCvMv3"},"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","# evaluator = COCOEvaluator(\"balloon_val\", output_dir=\"./output\")\n","# val_loader = build_detection_test_loader(cfg, \"balloon_val\")\n","# print(inference_on_dataset(predictor.model, val_loader, evaluator))\n","\n","evaluator = COCOEvaluator(\"abnormalities_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n","val_loader = build_detection_test_loader(cfg, \"abnormalities_val\")\n","results = inference_on_dataset(trainer.model, val_loader, evaluator)\n","\n","# another equivalent way to evaluate the model is to use `trainer.test`\n","val_loader = trai.build_test_loader(cfg, \"abnormalities_val\")\n","results = trainer.test(cfg, val_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iR2YiHfVW2DK"},"execution_count":null,"outputs":[]}]}